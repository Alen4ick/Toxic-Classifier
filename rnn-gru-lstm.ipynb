{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3586,"sourceType":"datasetVersion","datasetId":2134},{"sourceId":21206,"sourceType":"datasetVersion","datasetId":16074}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:40:49.630524Z","iopub.execute_input":"2024-02-19T15:40:49.630875Z","iopub.status.idle":"2024-02-19T15:41:02.658808Z","shell.execute_reply.started":"2024-02-19T15:40:49.630846Z","shell.execute_reply":"2024-02-19T15:41:02.657656Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2023.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gensim nltk\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:02.661221Z","iopub.execute_input":"2024-02-19T15:41:02.661863Z","iopub.status.idle":"2024-02-19T15:41:14.631888Z","shell.execute_reply.started":"2024-02-19T15:41:02.661821Z","shell.execute_reply":"2024-02-19T15:41:14.630790Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.24.4)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.4)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.4.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import datasets\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport gensim.downloader as api\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nimport torch\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm, trange\nfrom nltk.tokenize import WordPunctTokenizer\nfrom sklearn.utils.class_weight import compute_class_weight\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:14.633470Z","iopub.execute_input":"2024-02-19T15:41:14.634614Z","iopub.status.idle":"2024-02-19T15:41:31.223555Z","shell.execute_reply.started":"2024-02-19T15:41:14.634582Z","shell.execute_reply":"2024-02-19T15:41:31.222779Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"nltk.download('wordnet')\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:31.225793Z","iopub.execute_input":"2024-02-19T15:41:31.226295Z","iopub.status.idle":"2024-02-19T15:41:32.566911Z","shell.execute_reply.started":"2024-02-19T15:41:31.226268Z","shell.execute_reply":"2024-02-19T15:41:32.565968Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"df_all = pd.read_csv('/kaggle/input/cleaned-toxic-comments/train_preprocessed.csv')[['comment_text', 'toxic']]","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:32.568273Z","iopub.execute_input":"2024-02-19T15:41:32.568540Z","iopub.status.idle":"2024-02-19T15:41:34.084424Z","shell.execute_reply.started":"2024-02-19T15:41:32.568512Z","shell.execute_reply":"2024-02-19T15:41:34.083635Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train = df_all.sample(frac = 0.85)\ndf_test = df_all.drop(df_train.index)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:34.085679Z","iopub.execute_input":"2024-02-19T15:41:34.086140Z","iopub.status.idle":"2024-02-19T15:41:34.112744Z","shell.execute_reply.started":"2024-02-19T15:41:34.086107Z","shell.execute_reply":"2024-02-19T15:41:34.112039Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train['toxic'].value_counts(), df_test['toxic'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:34.113751Z","iopub.execute_input":"2024-02-19T15:41:34.114030Z","iopub.status.idle":"2024-02-19T15:41:34.131211Z","shell.execute_reply.started":"2024-02-19T15:41:34.114006Z","shell.execute_reply":"2024-02-19T15:41:34.130225Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(toxic\n 0.0    122606\n 1.0     13029\n Name: count, dtype: int64,\n toxic\n 0.0    21671\n 1.0     2265\n Name: count, dtype: int64)"},"metadata":{}}]},{"cell_type":"code","source":"class_weights = torch.from_numpy(compute_class_weight('balanced', classes = np.unique(df_train['toxic'].values), y = df_train['toxic'].values))\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:34.132280Z","iopub.execute_input":"2024-02-19T15:41:34.132580Z","iopub.status.idle":"2024-02-19T15:41:34.257715Z","shell.execute_reply.started":"2024-02-19T15:41:34.132557Z","shell.execute_reply":"2024-02-19T15:41:34.256880Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"tensor([0.5531, 5.2051], dtype=torch.float64)"},"metadata":{}}]},{"cell_type":"code","source":"type(class_weights)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:34.258955Z","iopub.execute_input":"2024-02-19T15:41:34.259636Z","iopub.status.idle":"2024-02-19T15:41:34.265134Z","shell.execute_reply.started":"2024-02-19T15:41:34.259603Z","shell.execute_reply":"2024-02-19T15:41:34.264186Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]},{"cell_type":"code","source":"word2vec = api.load('glove-twitter-50')","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:41:34.267715Z","iopub.execute_input":"2024-02-19T15:41:34.268232Z","iopub.status.idle":"2024-02-19T15:43:06.607320Z","shell.execute_reply.started":"2024-02-19T15:41:34.268208Z","shell.execute_reply":"2024-02-19T15:43:06.606524Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[========================================----------] 81.2% 162.0/199.5MB downloaded","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"[==================================================] 100.0% 199.5/199.5MB downloaded\n","output_type":"stream"}]},{"cell_type":"code","source":"word2vec.vectors.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:43:15.075160Z","iopub.execute_input":"2024-02-19T15:43:15.075525Z","iopub.status.idle":"2024-02-19T15:43:15.082110Z","shell.execute_reply.started":"2024-02-19T15:43:15.075495Z","shell.execute_reply":"2024-02-19T15:43:15.080987Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(1193514, 50)"},"metadata":{}}]},{"cell_type":"code","source":"word2index = {word: index for index, word in enumerate(word2vec.index_to_key)}","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:43:20.927649Z","iopub.execute_input":"2024-02-19T15:43:20.928016Z","iopub.status.idle":"2024-02-19T15:43:21.296536Z","shell.execute_reply.started":"2024-02-19T15:43:20.927988Z","shell.execute_reply":"2024-02-19T15:43:21.295648Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df):\n        self.df = df.dropna(subset = 'comment_text')\n        self.x = self.df['comment_text'].values\n        self.y = self.df['toxic'].fillna(-1).values\n    def __len__(self):\n        return len(self.x)\n    def __getitem__(self, idx):\n        return self.x[idx], torch.tensor(self.y[idx], dtype = torch.long)\n        \ntrain = MyDataset(df_train)\ntest = MyDataset(df_test)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:43:22.332189Z","iopub.execute_input":"2024-02-19T15:43:22.332551Z","iopub.status.idle":"2024-02-19T15:43:22.380176Z","shell.execute_reply.started":"2024-02-19T15:43:22.332522Z","shell.execute_reply":"2024-02-19T15:43:22.379348Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# preprocess\ndef preprocess_dataset(dataset, tokenyzer, lemmatizer, mapp):\n    for i in range(len(dataset.x)): \n        dataset.x[i] = tokenyzer.tokenize(dataset.x[i])\n        dataset.x[i] = [lemmatizer.lemmatize(word) for word in dataset.x[i]]\n        dataset.x[i] = torch.tensor([mapp[word] if word in mapp else mapp['unk'] for word in dataset.x[i]], \n                                   dtype = torch.long)\npreprocess_dataset(train, WordPunctTokenizer(), WordNetLemmatizer(), word2index)\npreprocess_dataset(test, WordPunctTokenizer(),  WordNetLemmatizer(), word2index)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:43:23.919849Z","iopub.execute_input":"2024-02-19T15:43:23.920574Z","iopub.status.idle":"2024-02-19T15:44:37.469080Z","shell.execute_reply.started":"2024-02-19T15:43:23.920543Z","shell.execute_reply":"2024-02-19T15:44:37.468217Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train[1]","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:44:50.001157Z","iopub.execute_input":"2024-02-19T15:44:50.001611Z","iopub.status.idle":"2024-02-19T15:44:50.011414Z","shell.execute_reply.started":"2024-02-19T15:44:50.001573Z","shell.execute_reply":"2024-02-19T15:44:50.010212Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(tensor([   305,   1290,     85,    175,    137,    568,  15688,   4649,    229,\n             96,     32,  62980,    137,    716,     39,     13,   6261,     26,\n             13,    469,     32,     13,   1258,   2002,     58,  21479,     16,\n             13,    325,     96,     13,   6762,  12865,     16,     56,     73,\n             55,     13,   1411,     11,     58,    469,   6762,     32,   4530,\n             33,     59,    775,  62980,    137,    716,     35,   7888,    153,\n           1897,     33,    551,    716,     33,     35,  27155,     58,  21479,\n             16,     13,   1258,   2002,     10,    186,  62980,     32,   5549,\n             45,     13,  87271,     39,     13,  40226, 118290,     32,  20223,\n         224031,     26,  44995,     26,     45,     74,     80,  10236,     45,\n         118290,     80,    276,    894,  10236,     13, 206230,   1258,   2002,\n             26,     13,  24479, 118290,     32,    175,     96,     13,  87271,\n             39,     13,  40226,   1258,   2002,     32,   8214,  44995,    267,\n             35,   6762,     13,   6261,     32,  31038,     11,  93511,  27383,\n          62980,  60953,   5840,   5718,  38180,    145,   3173,    285,     33,\n             32,  31038,     11,     11,   5895,    892,  60953,  40226,   4854,\n            682,   5718,     74,    631,     13, 206230,   1258,   2002,    183,\n            145,   1999,    240,     13,  40226,     96]),\n tensor(0))"},"metadata":{}}]},{"cell_type":"code","source":"test[0]","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:44:37.478539Z","iopub.execute_input":"2024-02-19T15:44:37.478820Z","iopub.status.idle":"2024-02-19T15:44:37.489920Z","shell.execute_reply.started":"2024-02-19T15:44:37.478797Z","shell.execute_reply":"2024-02-19T15:44:37.489009Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(tensor([   453,     15,    516,   5481, 134401,     26,   6655,     66,     21,\n            265,   3053,     13,   6006,   7016,    744,   1638, 401454,   2819,\n          57979,    187,    211,     16,  34349,     61,   7196,     33,    128,\n          28544,    183,     33,    273,     63,     15,     70,  44367,     61,\n           1426,     11,    172,   5072,    110,     13,   6006,   7016,     32,\n          14027,     53,     32,    896,     13,    731,    449,   4393,    121,\n           2466,  13313,    107,    615,     11,     39,    969,    249,  20608,\n             32,  48035,    765,    107,     32,     13,    214,   1704,   1311,\n           2683,    127,    195,     78,   6955,     45,    137,  10834,    145,\n          48035,    285,    249,  71153,    172,  62980,  32456,     10,  37907,\n             16, 132579,     53,   6006,     35,    420,     39,  75508,     13,\n           1823,     39,    172,   5072,     45,     32,   5680,     16,    273,\n             66,     13,   4649,   7016,     26,     78,   2109, 134401,    576,\n           2445,     55, 426237,   9555,     74,     15,  10908,     11,   2197,\n             39, 234242,    329,     15,    102,     43,     53,     80,    102,\n             64,     11,  51452,  11903,     46,     13,   7167,     26,  18309,\n             13,   1087,  50231]),\n tensor(0))"},"metadata":{}}]},{"cell_type":"code","source":"# writing function to handle data in batches\ndef collate_fn(batch):\n    max_len = max([len(data_tup[0]) for data_tup in batch])\n    input_embeddings = torch.empty((len(batch), max_len), dtype = torch.long)\n    labels = torch.empty(len(batch), dtype = torch.long)\n    for idx, data_tup in enumerate(batch):\n        to_pad = max_len - len(data_tup[0])\n        input_embeddings[idx] = torch.cat((data_tup[0], torch.zeros(to_pad)))\n        labels[idx] = data_tup[1]\n    return input_embeddings, labels","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:45:03.818391Z","iopub.execute_input":"2024-02-19T15:45:03.818776Z","iopub.status.idle":"2024-02-19T15:45:03.825651Z","shell.execute_reply.started":"2024-02-19T15:45:03.818720Z","shell.execute_reply":"2024-02-19T15:45:03.824701Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# creating DataLoaders to pass data in RNN,GRU,LSTM\ntrain_loader = DataLoader(train, batch_size = 32, shuffle = True, collate_fn = collate_fn)\ntest_loader = DataLoader(test, batch_size = 32, shuffle = True, collate_fn = collate_fn)\n\n\nloaders = {'train' : train_loader, 'test' : test_loader}","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:45:05.404032Z","iopub.execute_input":"2024-02-19T15:45:05.404633Z","iopub.status.idle":"2024-02-19T15:45:05.409938Z","shell.execute_reply.started":"2024-02-19T15:45:05.404601Z","shell.execute_reply":"2024-02-19T15:45:05.408999Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# writing out training function\ndef training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm = 1):\n    for e in trange(num_epochs, leave = False):\n        model.train()\n        num_iter = 0\n        pbar = tqdm(loaders['train'], leave = False)\n        for batch in pbar:\n            optimizer.zero_grad()\n            input_embeddings = batch[0].to(device)\n            labels = batch[1].long().to(device)\n            prediction = model(input_embeddings)\n            loss = criterion(prediction, labels)\n            loss.backward()\n            if max_grad_norm is not None:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n            optimizer.step()\n            num_iter += 1\n        valid_loss, valid_acc, num_iter = 0, 0, 0\n        model.eval()\n        with torch.no_grad():\n            correct, num_objs = 0, 0\n            for batch in loaders['test']:\n                input_embeddings = batch[0].to(device)\n                labels = batch[1].to(device)\n                prediction = model(input_embeddings)\n                valid_loss += criterion(prediction, labels)\n                correct += (labels == prediction.argmax(-1)).float().sum()\n                num_iter += 1\n                num_objs += len(labels)\n        print(f\"Valid loss: {valid_loss / num_iter}, accuracy: {correct / num_objs}\")\n        ","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:45:07.773004Z","iopub.execute_input":"2024-02-19T15:45:07.773845Z","iopub.status.idle":"2024-02-19T15:45:07.783415Z","shell.execute_reply.started":"2024-02-19T15:45:07.773807Z","shell.execute_reply":"2024-02-19T15:45:07.782555Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# RNN\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes = 2):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.embeddings = nn.Embedding.from_pretrained(torch.from_numpy(word2vec.vectors))\n        self.rnn = nn.RNN(input_size, hidden_size)\n        self.fc = nn.Linear(hidden_size, num_classes)\n    def forward(self, x):\n        x = self.embeddings(x)\n        x = x.permute(1, 0, 2)\n        output, h_n = self.rnn(x)\n        output = self.fc(h_n.squeeze(0)).float()\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:19:01.793295Z","iopub.execute_input":"2024-02-19T16:19:01.794059Z","iopub.status.idle":"2024-02-19T16:19:01.801098Z","shell.execute_reply.started":"2024-02-19T16:19:01.794023Z","shell.execute_reply":"2024-02-19T16:19:01.800058Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# initialize model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nrnn = RNN(word2vec.vector_size, 100).to(device)\nclass_weights = class_weights.float().to(device)\ncriterion = nn.CrossEntropyLoss(weight = class_weights)\noptimizer = torch.optim.Adam(rnn.parameters(), lr = 1e-2)\nnum_epochs = 10\nmax_grad_norm = 1.0","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:19:03.383377Z","iopub.execute_input":"2024-02-19T16:19:03.383775Z","iopub.status.idle":"2024-02-19T16:19:03.445147Z","shell.execute_reply.started":"2024-02-19T16:19:03.383708Z","shell.execute_reply":"2024-02-19T16:19:03.444167Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"training(rnn, criterion, optimizer, num_epochs, loaders, max_grad_norm)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:19:04.841952Z","iopub.execute_input":"2024-02-19T16:19:04.842322Z","iopub.status.idle":"2024-02-19T16:23:01.927346Z","shell.execute_reply.started":"2024-02-19T16:19:04.842289Z","shell.execute_reply":"2024-02-19T16:23:01.926392Z"},"trusted":true},"execution_count":73,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.6932706236839294, accuracy: 0.12052974849939346\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.6930031180381775, accuracy: 0.8809325098991394\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.7036470174789429, accuracy: 0.905372679233551\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 1.28517746925354, accuracy: 0.1534508764743805\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.992828905582428, accuracy: 0.14944016933441162\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.6913679242134094, accuracy: 0.905372679233551\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.6974291801452637, accuracy: 0.15223930776119232\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.6869073510169983, accuracy: 0.905372679233551\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.9922727346420288, accuracy: 0.8486798405647278\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 1.1134183406829834, accuracy: 0.8485127091407776\n","output_type":"stream"}]},{"cell_type":"code","source":"# lstm \nclass LSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes = 2):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.embeddings = nn.Embedding.from_pretrained(torch.from_numpy(word2vec.vectors))\n        self.lstm = nn.LSTM(input_size, hidden_size)\n        self.fc = nn.Linear(hidden_size, num_classes)\n    def forward(self, x):\n        x = self.embeddings(x).permute(1, 0, 2)\n        output, (hn, cn) = self.lstm(x)\n        output = self.fc(hn.squeeze(0)).float()\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:48:50.378531Z","iopub.execute_input":"2024-02-19T15:48:50.378921Z","iopub.status.idle":"2024-02-19T15:48:50.386086Z","shell.execute_reply.started":"2024-02-19T15:48:50.378888Z","shell.execute_reply":"2024-02-19T15:48:50.385095Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nlstm = LSTM(word2vec.vector_size, 100).to(device)\nclass_weights = class_weights.float().to(device)\ncriterion = nn.CrossEntropyLoss(weight = class_weights)\noptimizer = torch.optim.Adam(lstm.parameters(), lr = 1e-2)\nnum_epochs = 10\nmax_grad_norm = 1.0","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:48:51.293309Z","iopub.execute_input":"2024-02-19T15:48:51.294013Z","iopub.status.idle":"2024-02-19T15:48:51.353263Z","shell.execute_reply.started":"2024-02-19T15:48:51.293984Z","shell.execute_reply":"2024-02-19T15:48:51.352301Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"training(lstm, criterion, optimizer, num_epochs, loaders, max_grad_norm)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:48:52.172531Z","iopub.execute_input":"2024-02-19T15:48:52.173390Z","iopub.status.idle":"2024-02-19T15:53:58.877354Z","shell.execute_reply.started":"2024-02-19T15:48:52.173356Z","shell.execute_reply":"2024-02-19T15:53:58.876426Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.2815140187740326, accuracy: 0.9265123605728149\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.27866724133491516, accuracy: 0.9217497110366821\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.252873033285141, accuracy: 0.8922961354255676\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.250110000371933, accuracy: 0.8897894620895386\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.24674251675605774, accuracy: 0.8937583565711975\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.22431203722953796, accuracy: 0.9306901693344116\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.2362157702445984, accuracy: 0.9220421314239502\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.2331007719039917, accuracy: 0.9305648803710938\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.2460559904575348, accuracy: 0.9105531573295593\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4239 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Valid loss: 0.23309336602687836, accuracy: 0.9158172011375427\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_single(message, model, lemmatizer, tokenizer):\n    model.eval()\n    message = [lemmatizer.lemmatize(word) for word in tokenizer.tokenize(message)]\n    message = torch.tensor([word2index[word] if word in word2index else word2index[\"unk\"] for word in message])\n    batched_message = message.unsqueeze(0).to(device)\n    pred = model(batched_message)\n    return 'toxic' if (torch.sigmoid(pred[0][0]) < torch.sigmoid(pred[0][1])).item() else 'normal'","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:01:16.701633Z","iopub.execute_input":"2024-02-19T16:01:16.702589Z","iopub.status.idle":"2024-02-19T16:01:16.709645Z","shell.execute_reply.started":"2024-02-19T16:01:16.702549Z","shell.execute_reply":"2024-02-19T16:01:16.708464Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"pred = predict_single('It was great goal, probably best goal which i have ever seen', lstm, WordNetLemmatizer(), WordPunctTokenizer())","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:01:51.262138Z","iopub.execute_input":"2024-02-19T16:01:51.262524Z","iopub.status.idle":"2024-02-19T16:01:51.268971Z","shell.execute_reply.started":"2024-02-19T16:01:51.262492Z","shell.execute_reply":"2024-02-19T16:01:51.268124Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"comms = ['yo whats up my friend',\n         'how are you doing old fuck?', \n         \"i guess you going to your trash work again didn't you?\",\n        \"clean this trash can\"]\nfor comm in comms:\n    print(predict_single(comm, lstm, WordNetLemmatizer(), WordPunctTokenizer()))","metadata":{"execution":{"iopub.status.busy":"2024-02-19T16:24:25.239835Z","iopub.execute_input":"2024-02-19T16:24:25.240698Z","iopub.status.idle":"2024-02-19T16:24:25.735138Z","shell.execute_reply.started":"2024-02-19T16:24:25.240665Z","shell.execute_reply":"2024-02-19T16:24:25.733772Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"normal\ntoxic\ntoxic\ntoxic\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[85], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m comms \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myo whats up my friend\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhow are you doing old fuck?\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi guess you going to your trash work again didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt you?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean this trash can\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comm \u001b[38;5;129;01min\u001b[39;00m comms:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWordNetLemmatizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWordPunctTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[62], line 6\u001b[0m, in \u001b[0;36mpredict_single\u001b[0;34m(message, model, lemmatizer, tokenizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m message \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([word2index[word] \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word2index \u001b[38;5;28;01melse\u001b[39;00m word2index[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munk\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m message])\n\u001b[1;32m      5\u001b[0m batched_message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoxic\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39msigmoid(pred[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(pred[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[32], line 10\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m     output, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(hn\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"],"ename":"RuntimeError","evalue":"Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}